# <p align=center>Awesome AI in Beauty IndustryüíÑ</p>

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

A collection of resources on AI in the beauty and cosmetics industry.

## <span id="head-content"> *Content* </span>
* - [ ] [1. Description](#head1)

* - [ ] [2. Quantitative Evaluation Metrics](#head2)
  
* - [ ] [3. Datasets](#head3)  

* - [ ] [4. Paper With Code](#head4)
  * - [ ] [Survey](#head-Survey)
  * - [ ] [2023](#head-2023)
  * - [ ] [2022](#head-2022)
  * - [ ] [2021](#head-2021)
  * - [ ] [2020](#head-2020)
  * - [ ] [2019](#head-2019)
  * - [ ] [2018](#head-2018)

* [*Contact Me*](#head5)

## <span id="head1"> *1.Description* </span>
 
## <span id="head2"> *2.Quantitative Evaluation Metrics* </span>
 
## <span id="head3"> *3.Datasets* </span>
(Coming soon.)

## <span id="head4"> *4.Paper With Code* </span>

* <span id="head-Survey"> **Survey**  </span>

* <span id="head-2023"> **2023**  </span>
    *  (ACMMM 2023) [üí¨Fashion Synthesis] **SGDiff: A Style Guided Diffusion Model for Fashion Synthesis**, Zhengwentai Sun et al. [[Paper](https://arxiv.org/abs/2308.07605)] 
    *  (arXiv preprint 2023) [üí¨Fashion Design] **DiffFashion: Reference-based Fashion Design with Structure-aware Transfer by Diffusion Models**, Shidong Cao et al. [[Paper](https://arxiv.org/abs/2302.06826)]  [[Code](https://github.com/Rem105-210/DiffFashion)] 


* <span id="head-2022"> **2022**  </span>
    *  (Knowledge-Based Systems) [üí¨Makeup Transfer] **TSEV-GAN: Generative Adversarial Networks with Target-aware Style Encoding and Verification for facial makeup transfer**, Zhen Xu et al. [[Paper](https://www.sciencedirect.com/science/article/pii/S0950705122010516)]
    *  (ECCV 2022) [üí¨Hairstyle Transfer] **Style Your Hair: Latent Optimization for Pose-Invariant Hairstyle Transfer via Local-Style-Aware Hair Alignment**, Taewoo Kim et al. [[Paper](https://arxiv.org/abs/2208.07765)]  [[Code](https://github.com/Taeu/Style-Your-Hair)] 
    *  (ECCV 2022) [üí¨Makeup Transfer] **EleGANt: Exquisite and Locally Editable GAN for Makeup Transfer**, Chenyu Yang et al. [[Paper](https://arxiv.org/abs/2207.09840)]  [[Code](https://github.com/chenyu-yang-2000/elegant)] 
    *  (CVPR 2022) [üí¨Retouching] **ABPN: Adaptive Blend Pyramid Network for Real-Time Local Retouching of Ultra High-Resolution Photo**, Biwen Lei et al. [[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Lei_ABPN_Adaptive_Blend_Pyramid_Network_for_Real-Time_Local_Retouching_of_CVPR_2022_paper.pdf)]  [[Models](https://www.modelscope.cn/models/damo/cv_unet_skin-retouching/summary)] 
    *  (CVPR 2022) [üí¨Makeup Transfer & Protecting Facial Privacy] **Protecting Facial Privacy: Generating Adversarial Identity Masks via Style-robust Makeup Transfer**, Shengshan Hu et al. [[Paper](https://arxiv.org/abs/2203.03121)]
    *  (AAAI 2022) [üí¨Makeup Transfer & Removal] **SSAT: A Symmetric Semantic-Aware Transformer Network for Makeup Transfer and Removal**, Zhaoyang Sun et al. [[Paper](https://arxiv.org/abs/2112.03631)]  [[Code](https://github.com/Snowfallingplum/SSAT)] 


* <span id="head-2021"> **2021**  </span>
    *  (TPAMI 2021) [üí¨Makeup Transfer & Removal] **PSGAN++: Robust Detail-Preserving Makeup Transfer and Removal**, Si Liu et al. [[Paper](https://ieeexplore.ieee.org/abstract/document/9440729)]
    *  (CVPR 2021) [üí¨Makeup Transfer] **Spatially-invariant Style-codes Controlled Makeup Transfer**, Han Deng et al. [[Paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Deng_Spatially-Invariant_Style-Codes_Controlled_Makeup_Transfer_CVPR_2021_paper.pdf)]  [[Code](https://github.com/makeuptransfer/SCGAN)] 
    * (CVPR 2021 [AI for Content Creation Workshop](http://visual.cs.brown.edu/workshops/aicc2021/)) [üí¨Makeup Transfer for video] **Deep Graphics Encoder for Real-Time Video Makeup Synthesis from Example**, Robin Kips et al. [[Paper](https://openaccess.thecvf.com/content/CVPR2021W/CVFAD/papers/Kips_Deep_Graphics_Encoder_for_Real-Time_Video_Makeup_Synthesis_From_Example_CVPRW_2021_paper.pdf)] 
    * (CVPR 2021) [üí¨Makeup Transfer] **Lipstick ain't enough: Beyond Color Matching for In-the-Wild Makeup Transfer**, Thao Nguyen et al. [[Paper](https://arxiv.org/pdf/2104.01867.pdf)]  [[Code](https://github.com/VinAIResearch/CPM)] 
    * (IJCAI 2021) [üí¨Makeup Generation] **Adv-Makeup: A New Imperceptible and Transferable Attack on Face Recognition**, Bangjie Yin et al. [[Paper](https://arxiv.org/pdf/2105.03162.pdf)]

* <span id="head-2020"> **2020**  </span>
    *  (IJCAI 2020) [üí¨Makeup Transfer] **Real-World Automatic Makeup via Identity Preservation Makeup Net**, Zhikun Huang et al. [[Paper](https://www.ijcai.org/proceedings/2020/91)]  [[Code](https://github.com/huangzhikun1995/IPM-Net)] 
    *  (CVPR 2020) [üí¨Makeup Transfer] **PSGAN: Pose and Expression Robust Spatial-Aware GAN for Customizable Makeup Transfer**, Wentao Jiang et al. [[Paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Jiang_PSGAN_Pose_and_Expression_Robust_Spatial-Aware_GAN_for_Customizable_Makeup_CVPR_2020_paper.pdf)]  [[Code](https://github.com/wtjiang98/PSGAN)] 


* <span id="head-2019"> **2019**  </span>
    * (arXiv preprint 2019) [üí¨Makeup Transfer] **Disentangled Makeup Transfer with Generative Adversarial Network**, Honglun Zhang et al. [[Paper](https://arxiv.org/pdf/1907.01144.pdf)] [[Code](https://github.com/Honlan/DMT)] 
* <span id="head-2018"> **2018**  </span>

## <span id="head5"> *Contact Me* </span>

* [Yutong ZHOU](https://github.com/Yutong-Zhou-cv) in [Interaction Laboratory, Ritsumeikan University.](https://github.com/Rits-Interaction-Laboratory) „ÉΩ(Ôø£œâÔø£(Ôø£œâÔø£„ÄÉ)„Çù

* If you have any question, please feel free to contact Yutong ZHOU (E-mail: <zhou@i.ci.ritsumei.ac.jp>).
